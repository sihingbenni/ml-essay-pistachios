\begin{abstract}
Diese Arbeit entstand als Antwort auf die spezifische Aufgabenstellung, mindestens zwei Klassifikationsmethoden auf einen Datensatz anzuwenden, der mindestens 200 Elemente umfasst, Klassen aufweist, die nicht linear separierbar sind, und einen Merkmalsraum mit mindestens zwei Dimensionen besitzt. In dieser Studie wurden das k-Nächster-Nachbarn (k-NN)-Verfahren und Support-Vektor-Maschinen (SVM) zur Klassifikation zweier Pistazienarten verwendet. Die Untersuchung folgte einem strukturierten Ansatz, der eine explorative Datenanalyse, Datenbereinigung, Aufteilung in Trainings- und Testdaten, eine systematische Variation von Hyperparametern sowie deren Bewertung mit geeigneten Qualitätsmaßen umfasste. Die signifikante Verbesserung der Klassifikationsgenauigkeit durch Hyperparameter-Optimierung und Merkmalsnormalisierung demonstriert die Effektivität beider Methoden in diesem spezifischen Anwendungsfeld. Besondere Aufmerksamkeit wurde dem Einfluss von Hyperparametereinstellungen auf die Leistungsfähigkeit der Modelle gewidmet, wobei für k-NN durch die Variation des 'k'-Wertes und die Auswahl von sechs Merkmalen eine optimale Genauigkeit von 89,64 \% erreicht wurde. Im Vergleich dazu wurde durch die Anwendung eines systematischen \glqq{}GridSearch\grqq{}-Verfahrens zur Optimierung der Hyperparameter für SVM eine ähnlich hohe Leistung erzielt.
Die Ergebnisse bieten Einblicke in die Potenziale und Herausforderungen bei der Anwendung von k-NN und SVM in der nicht-linearen Klassifikation und unterstreichen die Bedeutung sorgfältiger Datenanalyse und -aufbereitung für die Modellgenauigkeit. Zukünftige Forschungen könnten sich auf die Vertiefung der Untersuchung von Overfitting konzentrieren, um die Generalisierbarkeit der Modelle zu verbessern. 

%Diese Studie bietet einen Überblick über die Anwendung des k-NN-Verfahrens zur Klassifikation von Daten unter besonderer Berücksichtigung von Skalierungs- und Normalisierungstechniken.
%Aufgrund des begrenzten Umfangs dieser Arbeit werden detaillierte Analysen, einschließlich umfassender Datenvisualisierungen und Codebeispiele, in einem ergänzenden Jupyter Notebook bereitgestellt, das für eine vertiefte Betrachtung herangezogen werden kann.
\end{abstract}
